{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahjamanbadhon/NLP/blob/main/Case_folding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9IkVxpFvCGJ"
      },
      "source": [
        "## Resources\n",
        "- https://nlp.stanford.edu/IR-book/html/htmledition/capitalizationcase-folding-1.html\n",
        "- https://tomelf.github.io/nlp/machine%20learning/text-preprocessing/\n",
        "- https://condor.depaul.edu/ntomuro/courses/575/notes/NLTK-intro.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMfYV300vCGO"
      },
      "source": [
        "## String casefold()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXgnw9NkvCGQ",
        "outputId": "cc373105-8fd3-49b3-e6bb-542fea8965fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "welcome to my natural language processing course!\n"
          ]
        }
      ],
      "source": [
        "text = \"Welcome To My Natural Language Processing Course!\"\n",
        "folded_text = text.casefold()\n",
        "print(folded_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPvYqcZ2vCGU"
      },
      "source": [
        "## Using string.to_lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X92vFeruvCGV",
        "outputId": "f131c6a8-8fd0-437a-f0bc-db8b600cd00e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "welcome to my natural language processing course!\n"
          ]
        }
      ],
      "source": [
        "lower_text=text.lower()\n",
        "print(lower_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGCLZIiOvCGW"
      },
      "source": [
        "## Case folding in Text Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxyXcDfevCGW",
        "outputId": "d5b11a53-2725-498b-896f-e4a7c24fbcff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAd9iI6evCGX",
        "outputId": "ccce7325-0d9d-44c0-9daa-24046531c19b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data. The goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\n"
          ]
        }
      ],
      "source": [
        "text='Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data. The goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.'\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uj2s5OIBvCGY",
        "outputId": "79e2e2e0-68ad-41c6-ac31-65f1db61a2b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'linguistics', ',', 'computer', 'science', ',', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'language', ',', 'in', 'particular', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data', '.', 'The', 'goal', 'is', 'a', 'computer', 'capable', 'of', '``', 'understanding', \"''\", 'the', 'contents', 'of', 'documents', ',', 'including', 'the', 'contextual', 'nuances', 'of', 'the', 'language', 'within', 'them', '.', 'The', 'technology', 'can', 'then', 'accurately', 'extract', 'information', 'and', 'insights', 'contained', 'in', 'the', 'documents', 'as', 'well', 'as', 'categorize', 'and', 'organize', 'the', 'documents', 'themselves', '.']\n"
          ]
        }
      ],
      "source": [
        "words=word_tokenize(text)\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NUfih3JvCGZ",
        "outputId": "c3ec9777-7bf0-4464-f763-82217311e87a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['natural', 'language', 'processing', '(', 'nlp', ')', 'is', 'a', 'subfield', 'of', 'linguistics', ',', 'computer', 'science', ',', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'language', ',', 'in', 'particular', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data', '.', 'the', 'goal', 'is', 'a', 'computer', 'capable', 'of', '``', 'understanding', \"''\", 'the', 'contents', 'of', 'documents', ',', 'including', 'the', 'contextual', 'nuances', 'of', 'the', 'language', 'within', 'them', '.', 'the', 'technology', 'can', 'then', 'accurately', 'extract', 'information', 'and', 'insights', 'contained', 'in', 'the', 'documents', 'as', 'well', 'as', 'categorize', 'and', 'organize', 'the', 'documents', 'themselves', '.']\n"
          ]
        }
      ],
      "source": [
        "words=[word.lower() for word in words]\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7VVTrJsvCGa",
        "outputId": "9db25110-8f49-4704-82d6-ac23c963bed2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'natural': 2,\n",
              "         'language': 4,\n",
              "         'processing': 1,\n",
              "         '(': 1,\n",
              "         'nlp': 1,\n",
              "         ')': 1,\n",
              "         'is': 2,\n",
              "         'a': 2,\n",
              "         'subfield': 1,\n",
              "         'of': 5,\n",
              "         'linguistics': 1,\n",
              "         ',': 4,\n",
              "         'computer': 2,\n",
              "         'science': 1,\n",
              "         'and': 5,\n",
              "         'artificial': 1,\n",
              "         'intelligence': 1,\n",
              "         'concerned': 1,\n",
              "         'with': 1,\n",
              "         'the': 8,\n",
              "         'interactions': 1,\n",
              "         'between': 1,\n",
              "         'computers': 2,\n",
              "         'human': 1,\n",
              "         'in': 2,\n",
              "         'particular': 1,\n",
              "         'how': 1,\n",
              "         'to': 2,\n",
              "         'program': 1,\n",
              "         'process': 1,\n",
              "         'analyze': 1,\n",
              "         'large': 1,\n",
              "         'amounts': 1,\n",
              "         'data': 1,\n",
              "         '.': 3,\n",
              "         'goal': 1,\n",
              "         'capable': 1,\n",
              "         '``': 1,\n",
              "         'understanding': 1,\n",
              "         \"''\": 1,\n",
              "         'contents': 1,\n",
              "         'documents': 3,\n",
              "         'including': 1,\n",
              "         'contextual': 1,\n",
              "         'nuances': 1,\n",
              "         'within': 1,\n",
              "         'them': 1,\n",
              "         'technology': 1,\n",
              "         'can': 1,\n",
              "         'then': 1,\n",
              "         'accurately': 1,\n",
              "         'extract': 1,\n",
              "         'information': 1,\n",
              "         'insights': 1,\n",
              "         'contained': 1,\n",
              "         'as': 2,\n",
              "         'well': 1,\n",
              "         'categorize': 1,\n",
              "         'organize': 1,\n",
              "         'themselves': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "Counter(words)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.13 ('tf-gpu')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "a42308a4b3b8692f798b54dd71ed0fc43b4ea9aee117f0b02f20461fbf01c221"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}